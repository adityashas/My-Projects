{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7657abd75f0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprocess_this_frame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Find all the faces and face encodings in the current frame of video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mface_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mface_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(face_encodings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mface_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m_raw_face_locations\u001b[0;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "#import create_csv\n",
    "\n",
    "from numpy import genfromtxt\n",
    "known_faces= genfromtxt('known_faces.txt')\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "video_capture = cv2.VideoCapture('rtsp://admin:Admin123@192.168.1.64:554/h264/ch05/sub/av_stream')\n",
    "#fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "#out = cv2.VideoWriter('xvidia2.avi',fourcc, 20.0, (int(video_capture.get(3)),int(video_capture.get(4))))\n",
    " \n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    " ret, frame = video_capture.read()\n",
    " \n",
    " if ret == True:\n",
    "    \n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    #print(\"inside loop\")\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(small_frame, number_of_times_to_upsample=2)\n",
    "        face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "        #print(face_encodings)\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            match = face_recognition.compare_faces(known_faces, face_encoding,tolerance=0.49)\n",
    "            name = \"Unknown\"\n",
    "            \n",
    "            if (match[0] or match[1]or match[2]or match[22]or match[23]or match[24]or match[25]or match[26]or match[27]):\n",
    "                name = \"Seshu\"\n",
    "            if (match[3] or match[4]or match[5]or match[28]or match[29]or match[30]or match[31]or match[32]):\n",
    "                name = \"Kritika\"\n",
    "            if match[6]:\n",
    "                name = \"Ravi\"\n",
    "            if (match[7] or match[8]or match[9]):\n",
    "                name = \"Madhur\"\n",
    "            if (match[10] or match[11]or match[12]):\n",
    "                name = \"upasana\"\n",
    "            if (match[13] or match[14]or match[15]or match[36]or match[37]or match[38]):\n",
    "                name = \"Arun\"\n",
    "            if (match[16] or match[17]or match[18] or match[33] or match[34]or match[35]):\n",
    "                name = \"Arjun\"\n",
    "            if match[19]:\n",
    "                name = \"Mrityunjay\"\n",
    "            if match[20]:\n",
    "                name = \"Rajan\"\n",
    "            if match[21]:\n",
    "                name = \"Mahender\"\n",
    "\n",
    "            \n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), 1)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    #out.write(frame)\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#CreateCsv(current_path + \"/face_database/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n",
    "counter=1\n",
    "from numpy import genfromtxt\n",
    "known_faces= genfromtxt('known_faces.txt')\n",
    "\n",
    "\n",
    "video_capture = cv2.VideoCapture('rtsp://admin:admin@192.168.1.200:554/cam/realmonitor?channel=1&subtype=1')\n",
    "fps1= video_capture.get(cv2.CAP_PROP_FPS)\n",
    "print(fps1)\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    " ret, frame = video_capture.read()\n",
    " \n",
    " if ret == True:\n",
    "   if (counter%7==0): \n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    #small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "# equalize the histogram of the Y channel\n",
    "    #small_frame[:,:,0] = cv2.equalizeHist(small_frame[:,:,0])\n",
    "\n",
    "# convert the YUV image back to RGB format\n",
    "    #small_frame = cv2.cvtColor(small_frame, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "    \n",
    "    #print(\"inside loop\")\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(small_frame, 3)\n",
    "        face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "        #print(face_encodings)\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            match = face_recognition.compare_faces(known_faces, face_encoding,tolerance=0.5)\n",
    "            \n",
    "            name = \"Unknown\"\n",
    "            \n",
    "            if (match[0] or match[1]or match[2]or match[22]or match[23]or match[24]or match[25]or match[26]or match[27]):\n",
    "                name = \"Seshu\"\n",
    "            if (match[3] or match[4]or match[5]or match[28]or match[29]or match[30]or match[31]or match[32]):\n",
    "                name = \"Kritika\"\n",
    "            if match[6]:\n",
    "                name = \"Ravi\"\n",
    "            if (match[7] or match[8]or match[9]):\n",
    "                name = \"Madhur\"\n",
    "            if (match[10] or match[11]or match[12]):\n",
    "                name = \"upasana\"\n",
    "            if (match[13] or match[14]or match[15]or match[36]or match[37]or match[38]):\n",
    "                name = \"Arun\"\n",
    "            if (match[16] or match[17]or match[18] or match[33] or match[34]or match[35]):\n",
    "                name = \"Arjun\"\n",
    "            if match[19]:\n",
    "                name = \"Mrityunjay\"\n",
    "            if match[20]:\n",
    "                name = \"Rajan\"\n",
    "            if match[21]:\n",
    "                name = \"Mahender\"\n",
    "            \n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), 1)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    #out.write(frame)\n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " counter=counter+1    \n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#CreateCsv(current_path + \"/face_database/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from threading import Thread\n",
    "import sys\n",
    "import cv2\n",
    " \n",
    "# import the Queue class from Python 3\n",
    "if sys.version_info >= (3, 0):\n",
    "\tfrom queue import Queue\n",
    " \n",
    "# otherwise, import the Queue class for Python 2.7\n",
    "else:\n",
    "\tfrom Queue import Queue\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileVideoStream:\n",
    "\tdef __init__(self, path, queueSize=128):\n",
    "\t\t# initialize the file video stream along with the boolean\n",
    "\t\t# used to indicate if the thread should be stopped or not\n",
    "\t\tself.stream = cv2.VideoCapture(path)\n",
    "\t\tself.stopped = False\n",
    " \n",
    "\t\t# initialize the queue used to store frames read from\n",
    "\t\t# the video file\n",
    "\t\tself.Q = Queue(maxsize=queueSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(self):\n",
    "\t\t# start a thread to read frames from the file video stream\n",
    "\t\tt = Thread(target=self.update, args=())\n",
    "\t\tt.daemon = True\n",
    "\t\tt.start()\n",
    "\t\treturn self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(self):\n",
    "\t\t# keep looping infinitely\n",
    "\t\twhile True:\n",
    "\t\t\t# if the thread indicator variable is set, stop the\n",
    "\t\t\t# thread\n",
    "\t\t\tif self.stopped:\n",
    "\t\t\t\treturn\n",
    " \n",
    "\t\t\t# otherwise, ensure the queue has room in it\n",
    "\t\t\tif not self.Q.full():\n",
    "\t\t\t\t# read the next frame from the file\n",
    "\t\t\t\t(grabbed, frame) = self.stream.read()\n",
    " \n",
    "\t\t\t\t# if the `grabbed` boolean is `False`, then we have\n",
    "\t\t\t\t# reached the end of the video file\n",
    "\t\t\t\tif not grabbed:\n",
    "\t\t\t\t\tself.stop()\n",
    "\t\t\t\t\treturn\n",
    " \n",
    "\t\t\t\t# add the frame to the queue\n",
    "\t\t\t\tself.Q.put(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(self):\n",
    "\t\t# return next frame in the queue\n",
    "\t\treturn self.Q.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
