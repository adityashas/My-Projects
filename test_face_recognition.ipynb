{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "facedetect = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#cap = cv2.VideoCapture(0)\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "#fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "#out = cv2.VideoWriter('test1.avi',fourcc, 20.0, (int(video_capture.get(3)),int(video_capture.get(4))))\n",
    "current_path = os.getcwd()\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "seshu_image = face_recognition.load_image_file(\"xvidia_staff/seshu/seshu.jpg\")\n",
    "seshu_face_encoding = face_recognition.face_encodings(seshu_image)[0]\n",
    "\n",
    "seshu2_image = face_recognition.load_image_file(\"xvidia_staff/seshu/seshu2.jpg\")\n",
    "seshu2_face_encoding = face_recognition.face_encodings(seshu2_image)[0]\n",
    "\n",
    "seshu3_image = face_recognition.load_image_file(\"xvidia_staff/seshu/seshu3.jpg\")\n",
    "seshu3_face_encoding = face_recognition.face_encodings(seshu3_image)[0]\n",
    "\n",
    "\n",
    "seshu4_image = face_recognition.load_image_file(\"xvidia_staff/seshu/1.jpg\")\n",
    "seshu4_face_encoding = face_recognition.face_encodings(seshu4_image)[0]\n",
    "\n",
    "seshu5_image = face_recognition.load_image_file(\"xvidia_staff/seshu/2.jpg\")\n",
    "seshu5_face_encoding = face_recognition.face_encodings(seshu5_image)[0]\n",
    "\n",
    "#seshu6_image = face_recognition.load_image_file(\"seshu/3.jpg\")\n",
    "#seshu6_face_encoding = face_recognition.face_encodings(seshu5_image)[0]\n",
    "\n",
    "seshu7_image = face_recognition.load_image_file(\"xvidia_staff/seshu/4.jpg\")\n",
    "seshu7_face_encoding = face_recognition.face_encodings(seshu7_image)[0]\n",
    "\n",
    "seshu8_image = face_recognition.load_image_file(\"xvidia_staff/seshu/5.jpg\")\n",
    "seshu8_face_encoding = face_recognition.face_encodings(seshu8_image)[0]\n",
    "\n",
    "seshu9_image = face_recognition.load_image_file(\"xvidia_staff/seshu/5.jpg\")\n",
    "seshu9_face_encoding = face_recognition.face_encodings(seshu9_image)[0]\n",
    "\n",
    "seshu10_image = face_recognition.load_image_file(\"xvidia_staff/seshu/7.jpg\")\n",
    "seshu10_face_encoding = face_recognition.face_encodings(seshu10_image)[0]\n",
    "\n",
    "\n",
    "kirtika_image = face_recognition.load_image_file(\"xvidia_staff/kritika/kritika.jpg\")\n",
    "kirtika_face_encoding = face_recognition.face_encodings(kirtika_image)[0]\n",
    "\n",
    "kirtika2_image = face_recognition.load_image_file(\"xvidia_staff/kritika/kritika3.jpg\")\n",
    "kirtika2_face_encoding = face_recognition.face_encodings(kirtika2_image)[0]\n",
    "\n",
    "kirtika3_image = face_recognition.load_image_file(\"xvidia_staff/kritika/1.jpg\")\n",
    "kirtika3_face_encoding = face_recognition.face_encodings(kirtika3_image)[0]\n",
    "\n",
    "kirtika4_image = face_recognition.load_image_file(\"xvidia_staff/kritika/2.jpg\")\n",
    "kirtika4_face_encoding = face_recognition.face_encodings(kirtika4_image)[0]\n",
    "\n",
    "kirtika5_image = face_recognition.load_image_file(\"xvidia_staff/kritika/3.jpg\")\n",
    "kirtika5_face_encoding = face_recognition.face_encodings(kirtika5_image)[0]\n",
    "\n",
    "kirtika6_image = face_recognition.load_image_file(\"xvidia_staff/kritika/4.jpg\")\n",
    "kirtika6_face_encoding = face_recognition.face_encodings(kirtika6_image)[0]\n",
    "\n",
    "kirtika7_image = face_recognition.load_image_file(\"xvidia_staff/kritika/5.jpg\")\n",
    "kirtika7_face_encoding = face_recognition.face_encodings(kirtika7_image)[0]\n",
    "\n",
    "kirtika8_image = face_recognition.load_image_file(\"xvidia_staff/kritika/6.jpg\")\n",
    "kirtika8_face_encoding = face_recognition.face_encodings(kirtika8_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "ravi_image = face_recognition.load_image_file(\"xvidia_staff/ravi/ravi.jpg\")\n",
    "ravi_face_encoding = face_recognition.face_encodings(ravi_image)[0]\n",
    "\n",
    "madhu_image = face_recognition.load_image_file(\"xvidia_staff/madhur/1.jpg\")\n",
    "madhu_face_encoding = face_recognition.face_encodings(madhu_image)[0]\n",
    "\n",
    "madhu2_image = face_recognition.load_image_file(\"xvidia_staff/madhur/2.jpg\")\n",
    "madhu2_face_encoding = face_recognition.face_encodings(madhu2_image)[0]\n",
    "\n",
    "madhu3_image = face_recognition.load_image_file(\"xvidia_staff/madhur/3.jpg\")\n",
    "madhu3_face_encoding = face_recognition.face_encodings(madhu3_image)[0]\n",
    "\n",
    "madhu4_image = face_recognition.load_image_file(\"xvidia_staff/madhur/4.jpg\")\n",
    "madhu4_face_encoding = face_recognition.face_encodings(madhu4_image)[0]\n",
    "\n",
    "\n",
    "madhu5_image = face_recognition.load_image_file(\"xvidia_staff/madhur/5.jpg\")\n",
    "madhu5_face_encoding = face_recognition.face_encodings(madhu5_image)[0]\n",
    "\n",
    "\n",
    "madhu6_image = face_recognition.load_image_file(\"xvidia_staff/madhur/6.jpg\")\n",
    "madhu6_face_encoding = face_recognition.face_encodings(madhu6_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "upasana_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana.jpg\")\n",
    "upasana_face_encoding = face_recognition.face_encodings(upasana_image)[0]\n",
    "\n",
    "upasana2_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana2.jpg\")\n",
    "upasana2_face_encoding = face_recognition.face_encodings(upasana2_image)[0]\n",
    "\n",
    "upasana3_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana3.jpg\")\n",
    "upasana3_face_encoding = face_recognition.face_encodings(upasana3_image)[0]\n",
    "\n",
    "upasana4_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana4.jpg\")\n",
    "upasana4_face_encoding = face_recognition.face_encodings(upasana4_image)[0]\n",
    "\n",
    "upasana5_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana5.jpg\")\n",
    "upasana5_face_encoding = face_recognition.face_encodings(upasana5_image)[0]\n",
    "\n",
    "upasana6_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana6.jpg\")\n",
    "upasana6_face_encoding = face_recognition.face_encodings(upasana6_image)[0]\n",
    "\n",
    "upasana7_image = face_recognition.load_image_file(\"xvidia_staff/upasana/upasana7.jpg\")\n",
    "upasana7_face_encoding = face_recognition.face_encodings(upasana7_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "arun_image = face_recognition.load_image_file(\"xvidia_staff/arun/arun.jpg\")\n",
    "arun_face_encoding = face_recognition.face_encodings(arun_image)[0]\n",
    "\n",
    "arun2_image = face_recognition.load_image_file(\"xvidia_staff/arun/arun2.jpg\")\n",
    "arun2_face_encoding = face_recognition.face_encodings(arun2_image)[0]\n",
    "\n",
    "#arun3_image = face_recognition.load_image_file(\"xvidia_staff/arun/arun3.jpg\")\n",
    "#arun3_face_encoding = face_recognition.face_encodings(arun3_image)[0]\n",
    "\n",
    "arun4_image = face_recognition.load_image_file(\"xvidia_staff/arun/arun4.jpg\")\n",
    "arun4_face_encoding = face_recognition.face_encodings(arun4_image)[0]\n",
    "\n",
    "\n",
    "arun5_image = face_recognition.load_image_file(\"xvidia_staff/arun/arun5.jpg\")\n",
    "arun5_face_encoding = face_recognition.face_encodings(arun5_image)[0]\n",
    "\n",
    "arun6_image = face_recognition.load_image_file(\"xvidia_staff/arun/arun6.jpg\")\n",
    "arun6_face_encoding = face_recognition.face_encodings(arun6_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "arjun_image = face_recognition.load_image_file(\"xvidia_staff/arjun/aaa.jpg\")\n",
    "arjun_face_encoding = face_recognition.face_encodings(arjun_image)[0]\n",
    "\n",
    "arjun2_image = face_recognition.load_image_file(\"xvidia_staff/arjun/arjun2.jpg\")\n",
    "arjun2_face_encoding = face_recognition.face_encodings(arjun2_image)[0]\n",
    "\n",
    "arjun3_image = face_recognition.load_image_file(\"xvidia_staff/arjun/arjun3.jpg\")\n",
    "arjun3_face_encoding = face_recognition.face_encodings(arjun3_image)[0]\n",
    "\n",
    "arjun4_image = face_recognition.load_image_file(\"xvidia_staff/arjun/arjun4.jpg\")\n",
    "arjun4_face_encoding = face_recognition.face_encodings(arjun4_image)[0]\n",
    "\n",
    "\n",
    "arjun5_image = face_recognition.load_image_file(\"xvidia_staff/arjun/arjun5.jpg\")\n",
    "arjun5_face_encoding = face_recognition.face_encodings(arjun5_image)[0]\n",
    "\n",
    "\n",
    "arjun6_image = face_recognition.load_image_file(\"xvidia_staff/arjun/arjun6.jpg\")\n",
    "arjun6_face_encoding = face_recognition.face_encodings(arjun6_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mrityunjay_image = face_recognition.load_image_file(\"xvidia_staff/mrityunjay/mrityunjay.jpg\")\n",
    "mrityunjay_face_encoding = face_recognition.face_encodings(mrityunjay_image)[0]\n",
    "\n",
    "\n",
    "rajan_image = face_recognition.load_image_file(\"xvidia_staff/rajan/rajan.jpg\")\n",
    "rajan_face_encoding = face_recognition.face_encodings(rajan_image)[0]\n",
    "\n",
    "mohinder_image = face_recognition.load_image_file(\"xvidia_staff/mahender/1.jpg\")\n",
    "mohinder_face_encoding = face_recognition.face_encodings(mohinder_image)[0]\n",
    "\n",
    "mohinder2_image = face_recognition.load_image_file(\"xvidia_staff/mahender/2.jpg\")\n",
    "mohinder2_face_encoding = face_recognition.face_encodings(mohinder2_image)[0]\n",
    "\n",
    "mohinder3_image = face_recognition.load_image_file(\"xvidia_staff/mahender/3.jpg\")\n",
    "mohinder3_face_encoding = face_recognition.face_encodings(mohinder3_image)[0]\n",
    "\n",
    "mohinder4_image = face_recognition.load_image_file(\"xvidia_staff/mahender/4.jpg\")\n",
    "mohinder4_face_encoding = face_recognition.face_encodings(mohinder4_image)[0]\n",
    "\n",
    "\n",
    "bhatia1_image = face_recognition.load_image_file(\"xvidia_staff/bhatia/bhatia1.jpg\")\n",
    "bhatia1_face_encoding = face_recognition.face_encodings(bhatia1_image)[0]\n",
    "\n",
    "bhatia2_image = face_recognition.load_image_file(\"xvidia_staff/bhatia/bhatia2.jpg\")\n",
    "bhatia2_face_encoding = face_recognition.face_encodings(bhatia2_image)[0]\n",
    "\n",
    "\n",
    "bhatia3_image = face_recognition.load_image_file(\"xvidia_staff/bhatia/bhatia9.jpg\")\n",
    "bhatia3_face_encoding = face_recognition.face_encodings(bhatia3_image)[0]\n",
    "\n",
    "\n",
    "bhatia4_image = face_recognition.load_image_file(\"xvidia_staff/bhatia/bhatia10.jpg\")\n",
    "bhatia4_face_encoding = face_recognition.face_encodings(bhatia4_image)[0]\n",
    "\n",
    "\n",
    "#bhatia5_image = face_recognition.load_image_file(\"xvidia_staff/bhatia/bhatia9.jpg\")\n",
    "#bhatia5_face_encoding = face_recognition.face_encodings(bhatia5_image)[0]\n",
    "\n",
    "vikas1_image = face_recognition.load_image_file(\"xvidia_staff/vikas/vikas1.jpg\")\n",
    "vikas1_face_encoding = face_recognition.face_encodings(vikas1_image)[0]\n",
    "\n",
    "vikas2_image = face_recognition.load_image_file(\"xvidia_staff/vikas/vikas2.jpg\")\n",
    "vikas2_face_encoding = face_recognition.face_encodings(vikas2_image)[0]\n",
    "\n",
    "subhash1_image = face_recognition.load_image_file(\"xvidia_staff/subhash/1.jpg\")\n",
    "subhash1_face_encoding = face_recognition.face_encodings(subhash1_image)[0]\n",
    "\n",
    "subhash2_image = face_recognition.load_image_file(\"xvidia_staff/subhash/2.jpg\")\n",
    "subhash2_face_encoding = face_recognition.face_encodings(subhash2_image)[0]\n",
    "\n",
    "\n",
    "subhash3_image = face_recognition.load_image_file(\"xvidia_staff/subhash/3.jpg\")\n",
    "subhash3_face_encoding = face_recognition.face_encodings(subhash3_image)[0]\n",
    "\n",
    "subhash4_image = face_recognition.load_image_file(\"xvidia_staff/subhash/4.jpg\")\n",
    "subhash4_face_encoding = face_recognition.face_encodings(subhash4_image)[0]\n",
    "\n",
    "\n",
    "\n",
    "known_faces = [seshu_face_encoding,seshu2_face_encoding,seshu3_face_encoding,seshu4_face_encoding,seshu5_face_encoding\n",
    "               ,seshu7_face_encoding,seshu8_face_encoding,seshu9_face_encoding,seshu10_face_encoding, \n",
    "               kirtika_face_encoding,kirtika2_face_encoding,kirtika3_face_encoding,kirtika4_face_encoding,kirtika5_face_encoding,\n",
    "               kirtika6_face_encoding,kirtika7_face_encoding,kirtika8_face_encoding,\n",
    "               ravi_face_encoding,\n",
    "               madhu_face_encoding,madhu2_face_encoding,madhu3_face_encoding,madhu4_face_encoding,madhu5_face_encoding,madhu6_face_encoding,\n",
    "               upasana_face_encoding,upasana2_face_encoding,upasana3_face_encoding,upasana4_face_encoding,upasana5_face_encoding,upasana6_face_encoding,upasana7_face_encoding,\n",
    "               arun_face_encoding,arun2_face_encoding,arun4_face_encoding,arun5_face_encoding,arun6_face_encoding,\n",
    "               arjun_face_encoding,arjun2_face_encoding,arjun3_face_encoding,arjun4_face_encoding,arjun5_face_encoding,arjun6_face_encoding,\n",
    "               mrityunjay_face_encoding,\n",
    "               rajan_face_encoding,\n",
    "               mohinder_face_encoding,mohinder2_face_encoding,mohinder3_face_encoding,mohinder4_face_encoding,\n",
    "              bhatia1_face_encoding,bhatia2_face_encoding ,bhatia3_face_encoding ,bhatia4_face_encoding,\n",
    "              vikas1_face_encoding,vikas2_face_encoding, \n",
    "              subhash1_face_encoding,subhash2_face_encoding,subhash3_face_encoding,subhash4_face_encoding]    \n",
    "#print(madhu_face_encoding)\n",
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#known_faces=np.array(known_faces)\n",
    "\n",
    "#known_faces.tofile('known_faces.csv',sep=',',format='%10.5f')\n",
    "np.savetxt('known_faces.txt', known_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-57ab4aa30aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Find all the faces and face encodings in the current frame of video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mface_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mface_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m#print(face_encodings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mface_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36mface_encodings\u001b[0;34m(face_image, known_face_locations, num_jitters)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mraw_landmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_face_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_face_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_face_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_landmark_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jitters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mraw_landmark_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_landmarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mraw_landmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_face_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknown_face_locations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_face_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_landmark_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jitters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mraw_landmark_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_landmarks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import pyttsx\n",
    "#import create_csv\n",
    "engine = pyttsx.init()\n",
    "#import create_csv\n",
    "\n",
    "from numpy import genfromtxt\n",
    "known_faces= genfromtxt('known_faces.txt')\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "counter=2\n",
    "#video_capture = cv2.VideoCapture(\"rtsp://admin:admin@192.168.1.200:554/cam/realmonitor?channel=1&subtype=0\")\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    " #if (counter%8==0): \n",
    "  ret, frame = video_capture.read()\n",
    " \n",
    "  if ret == True:\n",
    "    \n",
    "    # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    #print(\"inside loop\")\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(small_frame, number_of_times_to_upsample=1)\n",
    "        face_encodings = face_recognition.face_encodings(small_frame, face_locations)\n",
    "        #print(face_encodings)\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            match = face_recognition.compare_faces(known_faces, face_encoding,tolerance=0.40)\n",
    "            name = \"Unknown\"\n",
    "            \n",
    "            if (match[0] or match[1]or match[2]or match[3]or match[4]or match[5]or match[6]or match[7]or match[8]):\n",
    "                name = \"Seshu\"\n",
    "            if (match[9] or match[10]or match[11]or match[12]or match[13]or match[14]or match[15]or match[16]):\n",
    "                name = \"Kritika\"\n",
    "            if match[17]:\n",
    "                name = \"Ravi\"\n",
    "            if (match[18] or match[19]or match[20]or match[21]or match[22]or match[23]):\n",
    "                name = \"Madhur\"\n",
    "            if (match[24] or match[25]or match[26]or match[27]or match[28]or match[29]or match[30]):\n",
    "                name = \"upasana\"\n",
    "            if (match[31] or match[32]or match[33]or match[34]or match[35]):\n",
    "                name = \"Arun\"\n",
    "            if (match[36] or match[37]or match[38] or match[39] or match[40]or match[41]):\n",
    "                name = \"Arjun\"\n",
    "            if match[42]:\n",
    "                name = \"Mrityunjay\"\n",
    "            if match[43]:\n",
    "                name = \"Rajan\"\n",
    "            if (match[44]or match[45]or match[46]or match[47]):\n",
    "                name = \"Mahender\"\n",
    "            if match[48]or match[49]or match[50]or match[51]:\n",
    "                name = \"P.K.Bhatia\"\n",
    "            if match[52]or match[53]:\n",
    "                name = \"Vikas\"\n",
    "            if match[54]or match[55]or match[56]or match[57]:\n",
    "                name = \"Subhash\"\n",
    "\n",
    "            \n",
    "            face_names.append(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), 1)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "        if name!=\"Unknown\":\n",
    "            engine.say(str(name))\n",
    "            time.sleep(0.19)\n",
    "            engine.runAndWait()\n",
    "            #k=input()\n",
    "            #continue\n",
    "    # Display the resulting image\n",
    "    \n",
    "    cv2.imshow('Video', frame)\n",
    "    \n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " #counter=counter+1    \n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "counter=counter+1\n",
    "#CreateCsv(current_path + \"/face_database/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
