{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "from PIL import Image\n",
    "path=\"Type_1/\"\n",
    "\n",
    "new_path=\"Type_1_128/\"\n",
    "\n",
    "dirs=os.listdir(path)\n",
    "for item in dirs:\n",
    " if item==('.DS_Store' ):\n",
    "    continue\n",
    " if str(item)=='1339.jpg':\n",
    "    continue\n",
    " #print item\n",
    " if os.path.isfile(path+item):\n",
    "    im=Image.open(path+item)\n",
    "    f,e=os.path.splitext(new_path+item)\n",
    "    imResize=im.resize((128,128),Image.ANTIALIAS)\n",
    "    imResize.save(f+'.jpg','JPEG',quality=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path=\"Type_2/\"\n",
    "\n",
    "new_path=\"Type_2_128/\"\n",
    "dirs=os.listdir(path)\n",
    "\n",
    "for item in dirs:\n",
    " if item==('.DS_Store' ):\n",
    "    continue\n",
    " \n",
    " if os.path.isfile(path+item):\n",
    "    im=Image.open(path+item)\n",
    "    f,e=os.path.splitext(new_path+item)\n",
    "    imResize=im.resize((128,128),Image.ANTIALIAS)\n",
    "    imResize.save(f+'.jpg','JPEG',quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=\"Type_3/\"\n",
    "\n",
    "new_path=\"Type_3_128/\"\n",
    "dirs=os.listdir(path)\n",
    "\n",
    "for item in dirs:\n",
    " if item==('.DS_Store' ):\n",
    "    continue\n",
    " if os.path.isfile(path+item):\n",
    "    im=Image.open(path+item)\n",
    "    f,e=os.path.splitext(new_path+item)\n",
    "    imResize=im.resize((128,128),Image.ANTIALIAS)\n",
    "    imResize.save(f+'.jpg','JPEG',quality=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "my_path='Type_1_128'\n",
    "only_files=[f for f in listdir(my_path) if isfile(join(my_path,f))]\n",
    "only_files.sort(key=lambda f:int(filter(str.isdigit,f)))\n",
    "images_1=np.empty(len(only_files),dtype=object)\n",
    "for n in range(0,len(only_files)):\n",
    " images_1[n]=cv2.imread(join(my_path,only_files[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "print images_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "my_path='Type_2_128'\n",
    "only_files=[f for f in listdir(my_path) if isfile(join(my_path,f))]\n",
    "only_files.sort(key=lambda f:int(filter(str.isdigit,f)))\n",
    "images_2=np.empty(len(only_files),dtype=object)\n",
    "for n in range(0,len(only_files)):\n",
    " images_2[n]=cv2.imread(join(my_path,only_files[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(781,)\n"
     ]
    }
   ],
   "source": [
    "print images_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "from os.path import isfile,join\n",
    "my_path='Type_3_128'\n",
    "only_files=[f for f in listdir(my_path) if isfile(join(my_path,f))]\n",
    "only_files.sort(key=lambda f:int(filter(str.isdigit,f)))\n",
    "images_3=np.empty(len(only_files),dtype=object)\n",
    "for n in range(0,len(only_files)):\n",
    " images_3[n]=cv2.imread(join(my_path,only_files[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450,)\n"
     ]
    }
   ],
   "source": [
    "print images_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(images_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images=np.concatenate((images_1, images_2,images_3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480,)\n"
     ]
    }
   ],
   "source": [
    "print images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels=list()\n",
    "for i in range (0,249):\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,781):\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range (0,450):\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1480\n"
     ]
    }
   ],
   "source": [
    "print len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_size=1480\n",
    "\n",
    "def create_sequences():\n",
    " dataset=np.ndarray(shape=(1480,128,128,3),dtype=np.float32) \n",
    " data_labels=[]\n",
    " i=0\n",
    " w=0\n",
    " while i<data_size:\n",
    "        #print images_1[i].shape\n",
    "        temp=np.hstack([images[i]])\n",
    "        dataset[i,:,:]=temp\n",
    "        temp_str=str(labels[i])\n",
    "        data_labels.append(labels[i])\n",
    "        \n",
    "        w+=1\n",
    "        i+=1\n",
    "        np.array(data_labels)\n",
    " return dataset,data_labels\n",
    "dataset,data_labels=create_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1480, 128, 128, 3)\n",
      "1480\n"
     ]
    }
   ],
   "source": [
    "print dataset.shape\n",
    "print len(data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(data_labels,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seshaditya/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(dataset,y,test_size=0.2,random_state=369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from PIL import Image\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import display \n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "%matplotlib inline\n",
    "import random\n",
    "import math\n",
    "from IPython.display import Image\n",
    "from scipy import ndimage\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (64, 64), padding=\"same\", activation=\"relu\", input_shape=(64, 64, 3...)`\n",
      "  import sys\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (40, 40), padding=\"same\", activation=\"relu\")`\n",
      "  \n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (20, 20), padding=\"same\", activation=\"relu\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (64, 64), padding=\"same\", activation=\"relu\", input_shape=(128, 128,...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (32, 32), padding=\"same\", activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (16, 16), padding=\"same\", activation=\"relu\")`\n",
      "  if sys.path[0] == '':\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (8, 8), padding=\"same\", activation=\"relu\")`\n",
      "  del sys.path[0]\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (4, 4), padding=\"same\", activation=\"relu\")`\n",
      "  \n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (5, 5), padding=\"same\", activation=\"relu\")`\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (5, 5), padding=\"same\", activation=\"relu\")`\n",
      "  app.launch_new_instance()\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4096, (5, 5), padding=\"same\", activation=\"relu\")`\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:18: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (2, 2), padding=\"same\", activation=\"relu\")`\n",
      "/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/ipykernel_launcher.py:62: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"de..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Convolution2D,MaxPooling2D\n",
    "from keras.layers import Dense,Input, Dropout,Flatten\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "\n",
    "inputs=Input(shape=(128,128,3))\n",
    "conv1_1=Convolution2D(4,64,64, border_mode='same',input_shape=(64,64,3),activation='relu')\n",
    "conv1_2=Convolution2D(8,40,40, border_mode='same',activation='relu')\n",
    "conv1_3=Convolution2D(16,20,20, border_mode='same',activation='relu')\n",
    "conv1=Convolution2D(32,64,64, border_mode='same',input_shape=(128,128,3),activation='relu')\n",
    "conv2=Convolution2D(64,32,32,border_mode='same',activation='relu')\n",
    "conv3=Convolution2D(128,16,16, border_mode='same',activation='relu')\n",
    "conv4=Convolution2D(256,8,8, border_mode='same',activation='relu')\n",
    "conv5=Convolution2D(512,4,4, border_mode='same',activation='relu')\n",
    "conv6=Convolution2D(1024,5,5, border_mode='same',activation='relu')\n",
    "conv7=Convolution2D(2048,5,5, border_mode='same',activation='relu')\n",
    "conv8=Convolution2D(4096,5,5, border_mode='same',activation='relu')\n",
    "conv7=Convolution2D(2048,2,2, border_mode='same',activation='relu')\n",
    "x=conv1(inputs)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=conv2(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=conv3(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=conv4(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=conv5(x)\n",
    "x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "#x=conv6(x)\n",
    "#x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "#x=conv7(x)\n",
    "#x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "#x=conv8(x)\n",
    "#x=MaxPooling2D(pool_size=(2,2))(x)\n",
    "x=Flatten()(x)\n",
    "\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(4500,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(4000,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(3500,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(3000,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(2500,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(2000,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(1500,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(1200,activation='relu')(x)\n",
    "x=Dropout(0.3)(x)\n",
    "x=Dense(1000,activation='relu')(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(500,activation='relu')(x)\n",
    "x=Dropout(0.2)(x)\n",
    "x=Dense(200,activation='relu')(x)\n",
    "x=Dropout(0.2)(x)\n",
    "pred=Dense(3,activation='softmax')(x)\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model=Model(input=inputs,output=pred)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1184 samples, validate on 296 samples\n",
      "Epoch 1/10\n",
      "1184/1184 [==============================] - 2014s - loss: 7.3964 - acc: 0.5253 - val_loss: 7.7868 - val_acc: 0.5169\n",
      "Epoch 2/10\n",
      " 320/1184 [=======>......................] - ETA: 1345s - loss: 7.5050 - acc: 0.5344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6d77e20be432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/seshaditya/anaconda2/envs/keras-test/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=10, batch_size=32,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "K.set_floatx('float32')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(17)\n",
    "\n",
    "train_data = np.load('train.npy')\n",
    "train_target = np.load('train_target.npy')\n",
    "\n",
    "x_train,x_val_train,y_train,y_val_train = train_test_split(train_data,train_target,test_size=0.4, random_state=17)\n",
    "\n",
    "def create_model(opt_='adamax'):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(4, 3, 3, activation='relu', dim_ordering='th', input_shape=(3, 32, 32))) #use input_shape=(3, 64, 64)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "    model.add(Convolution2D(8, 3, 3, activation='relu', dim_ordering='th'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering='th'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(12, activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=opt_, loss='sparse_categorical_crossentropy', metrics=['accuracy']) \n",
    "    return model\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=0.3, zoom_range=0.3)\n",
    "datagen.fit(train_data)\n",
    "\n",
    "model = create_model()\n",
    "model.fit_generator(datagen.flow(x_train,y_train, batch_size=15, shuffle=True), nb_epoch=200, samples_per_epoch=len(x_train), verbose=20, validation_data=(x_val_train, y_val_train))\n",
    "\n",
    "test_data = np.load('test.npy')\n",
    "test_id = np.load('test_id.npy')\n",
    "\n",
    "pred = model.predict_proba(test_data)\n",
    "df = pd.DataFrame(pred, columns=['Type_1','Type_2','Type_3'])\n",
    "df['image_name'] = test_id\n",
    "df.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import ImageFilter, ImageStat, Image, ImageDraw\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "def im_multi(path):\n",
    "    try:\n",
    "        im_stats_im_ = Image.open(path)\n",
    "        return [path, {'size': im_stats_im_.size}]\n",
    "    except:\n",
    "        print(path)\n",
    "        return [path, {'size': [0,0]}]\n",
    "\n",
    "def im_stats(im_stats_df):\n",
    "    im_stats_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(im_multi, im_stats_df['path'])\n",
    "    for i in range(len(ret)):\n",
    "        im_stats_d[ret[i][0]] = ret[i][1]\n",
    "    im_stats_df['size'] = im_stats_df['path'].map(lambda x: ' '.join(str(s) for s in im_stats_d[x]['size']))\n",
    "    return im_stats_df\n",
    "\n",
    "def get_im_cv2(path):\n",
    "    img = cv2.imread(path)\n",
    "    resized = cv2.resize(img, (32, 32), cv2.INTER_LINEAR) #use cv2.resize(img, (64, 64), cv2.INTER_LINEAR)\n",
    "    return [path, resized]\n",
    "\n",
    "def normalize_image_features(paths):\n",
    "    imf_d = {}\n",
    "    p = Pool(cpu_count())\n",
    "    ret = p.map(get_im_cv2, paths)\n",
    "    for i in range(len(ret)):\n",
    "        imf_d[ret[i][0]] = ret[i][1]\n",
    "    ret = []\n",
    "    fdata = [imf_d[f] for f in paths]\n",
    "    fdata = np.array(fdata, dtype=np.uint8)\n",
    "    fdata = fdata.transpose((0, 3, 1, 2))\n",
    "    fdata = fdata.astype('float32')\n",
    "    fdata = fdata / 255\n",
    "    return fdata\n",
    "\n",
    "train = glob.glob('../input/train/**/*.jpg') + glob.glob('../input/additional/**/*.jpg')\n",
    "train = pd.DataFrame([[p.split('/')[3],p.split('/')[4],p] for p in train], columns = ['type','image','path'])[::5] #limit for Kaggle Demo\n",
    "train = im_stats(train)\n",
    "train = train[train['size'] != '0 0'].reset_index(drop=True) #remove bad images\n",
    "train_data = normalize_image_features(train['path'])\n",
    "np.save('train.npy', train_data, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "train_target = le.fit_transform(train['type'].values)\n",
    "print(le.classes_) #in case not 1 to 3 order\n",
    "np.save('train_target.npy', train_target, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "test = glob.glob('../input/test/*.jpg')\n",
    "test = pd.DataFrame([[p.split('/')[3],p] for p in test], columns = ['image','path']) #[::20] #limit for Kaggle Demo\n",
    "test_data = normalize_image_features(test['path'])\n",
    "np.save('test.npy', test_data, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "test_id = test.image.values\n",
    "np.save('test_id.npy', test_id, allow_pickle=True, fix_imports=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
